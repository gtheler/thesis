KSP Object: 1 MPI process
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances: relative=1e-06, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 1 MPI process
  type: gamg
    type is MULTIPLICATIVE, levels=4 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   0.   0.   0.   0.  
        Threshold scaling factor for each level not specified = 1.
        AGG specific options
          Number of levels of aggressive coarsening 1
          Square graph aggressive coarsening
          Number smoothing steps 1
        Complexity:    grid = 1.01213    operator = 1.03247
  Coarse grid solver -- level 0 -------------------------------
    KSP Object: (mg_coarse_) 1 MPI process
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_coarse_) 1 MPI process
      type: bjacobi
        number of blocks = 1
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -mg_coarse_ksp_view ::ascii_info_detail to display information for all blocks
        KSP Object: (mg_coarse_sub_) 1 MPI process
          type: preonly
          maximum iterations=1, initial guess is zero
          tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
          left preconditioning
          using NONE norm type for convergence test
        PC Object: (mg_coarse_sub_) 1 MPI process
          type: lu
            out-of-place factorization
            tolerance for zero pivot 2.22045e-14
            using diagonal shift on blocks to prevent zero pivot [INBLOCKS]
            matrix ordering: nd
            factor fill ratio given 5., needed 1.
              Factored matrix follows:
                Mat Object: (mg_coarse_sub_) 1 MPI process
                  type: seqaij
                  rows=6, cols=6, bs=2
                  package used to perform factorization: petsc
                  total: nonzeros=36, allocated nonzeros=36
                    using I-node routines: found 2 nodes, limit used is 5
          linear system matrix = precond matrix:
          Mat Object: (mg_coarse_sub_) 1 MPI process
            type: seqaij
            rows=6, cols=6, bs=2
            total: nonzeros=36, allocated nonzeros=36
            total number of mallocs used during MatSetValues calls=0
              using I-node routines: found 2 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: (mg_coarse_sub_) 1 MPI process
        type: seqaij
        rows=6, cols=6, bs=2
        total: nonzeros=36, allocated nonzeros=36
        total number of mallocs used during MatSetValues calls=0
          using I-node routines: found 2 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 1 MPI process
      type: chebyshev
        Chebyshev polynomial of first kind
        eigenvalue targets used: min 0.129179, max 1.42096
        eigenvalues provided (min 0.252772, max 1.29179) with transform: [0. 0.1; 0. 1.1]
      maximum iterations=2, nonzero initial guess
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 1 MPI process
      type: jacobi
        type DIAGONAL
      linear system matrix = precond matrix:
      Mat Object: 1 MPI process
        type: seqaij
        rows=112, cols=112, bs=2
        total: nonzeros=10752, allocated nonzeros=10752
        total number of mallocs used during MatSetValues calls=0
          using I-node routines: found 55 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 1 MPI process
      type: chebyshev
        Chebyshev polynomial of first kind
        eigenvalue targets used: min 0.183068, max 2.01375
        eigenvalues provided (min 0.0784585, max 1.83068) with transform: [0. 0.1; 0. 1.1]
      maximum iterations=2, nonzero initial guess
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 1 MPI process
      type: jacobi
        type DIAGONAL
      linear system matrix = precond matrix:
      Mat Object: 1 MPI process
        type: seqaij
        rows=3000, cols=3000, bs=2
        total: nonzeros=465688, allocated nonzeros=465688
        total number of mallocs used during MatSetValues calls=0
          using I-node routines: found 1499 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 3 -------------------------------
    KSP Object: (mg_levels_3_) 1 MPI process
      type: chebyshev
        Chebyshev polynomial of first kind
        eigenvalue targets used: min 0.773661, max 8.51027
        eigenvalues provided (min 0.231635, max 7.73661) with transform: [0. 0.1; 0. 1.1]
      maximum iterations=2, nonzero initial guess
      tolerances: relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_3_) 1 MPI process
      type: jacobi
        type DIAGONAL
      linear system matrix = precond matrix:
      Mat Object: K_bc 1 MPI process
        type: seqaij
        rows=256964, cols=256964, bs=2
        total: nonzeros=14674240, allocated nonzeros=14674240
        total number of mallocs used during MatSetValues calls=0
          using I-node routines: found 128482 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: K_bc 1 MPI process
    type: seqaij
    rows=256964, cols=256964, bs=2
    total: nonzeros=14674240, allocated nonzeros=14674240
    total number of mallocs used during MatSetValues calls=0
      using I-node routines: found 128482 nodes, limit used is 5
size = 256964	time = 11.2 s	 memory = 0.8 Gb
[0/1 LIN54Z7SQ3] local memory = 0.8 Gb
****************************************************************************************************************************************************************
***                                WIDEN YOUR WINDOW TO 160 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document                                 ***
****************************************************************************************************************************************************************

------------------------------------------------------------------ PETSc Performance Summary: ------------------------------------------------------------------

/home/jtheler/feenox/feenox-gnu on a release-gnu named LIN54Z7SQ3 with 1 process, by jtheler on Thu May 16 19:36:54 2024
Using Petsc Development GIT revision: v3.21.1-175-gcef0416bfaf  GIT Date: 2024-05-15 19:29:27 +0000

                         Max       Max/Min     Avg       Total
Time (sec):           8.978e+00     1.000   8.978e+00
Objects:              0.000e+00     0.000   0.000e+00
Flops:                9.970e+09     1.000   9.970e+09  9.970e+09
Flops/sec:            1.110e+09     1.000   1.110e+09  1.110e+09
MPI Msg Count:        0.000e+00     0.000   0.000e+00  0.000e+00
MPI Msg Len (bytes):  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flops
                            and VecAXPY() for complex vectors of length N --> 8N flops

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.0325e-01   4.5%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 1:            init: 4.9242e-03   0.1%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 2:           build: 3.1920e+00  35.6%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 3:           solve: 5.3697e+00  59.8%  9.9699e+09 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 4:            post: 7.9798e-03   0.1%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage


--- Event Stage 1: init


--- Event Stage 2: build

MatConvert             1 1.0 4.7496e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
MatAssemblyBegin       1 1.0 9.0000e-08 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         1 1.0 7.1562e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  8  0  0  0  0  22  0  0  0  0     0
MatSetValues      354395 1.0 2.5669e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 29  0  0  0  0  80  0  0  0  0     0
MatZeroEntries         1 1.0 4.4500e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecCopy                1 1.0 1.0286e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyBegin       2 1.0 1.9800e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         2 1.0 2.6600e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSetValues       97431 1.0 1.3926e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0

--- Event Stage 3: solve

MatMult              692 1.0 2.5720e+00 1.0 7.88e+09 1.0 0.0e+00 0.0e+00 0.0e+00 29 79  0  0  0  48 79  0  0  0  3065
MatMultAdd           153 1.0 8.0477e-02 1.0 2.30e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0  2862
MatMultTranspose     153 1.0 1.0078e-01 1.0 2.30e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   2  2  0  0  0  2285
MatSolve              51 1.0 2.7630e-05 1.0 3.37e+03 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   122
MatLUFactorSym         1 1.0 5.0790e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatLUFactorNum         1 1.0 1.7080e-06 1.0 1.29e+02 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    76
MatScale               9 1.0 6.5038e-03 1.0 1.21e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  1859
MatResidual          153 1.0 5.1319e-01 1.0 1.55e+09 1.0 0.0e+00 0.0e+00 0.0e+00  6 16  0  0  0  10 16  0  0  0  3011
MatAssemblyBegin      30 1.0 2.6440e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd        30 1.0 1.8598e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatSetValues      783343 1.0 1.3374e-01 1.0 4.31e+06 1.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0    32
MatGetRow        1170401 1.0 3.3807e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
MatGetRowIJ            1 1.0 9.1300e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 1.2875e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatCoarsen             3 1.0 1.5883e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatView                7 1.0 1.0658e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAXPY                6 1.0 1.3109e-01 1.0 4.31e+06 1.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0    33
MatTranspose           5 1.0 3.3593e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
MatMatMultSym          3 1.0 6.2525e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
MatMatMultNum          3 1.0 3.9966e-02 1.0 6.29e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   1  1  0  0  0  1573
MatPtAPSymbolic        3 1.0 2.5213e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   5  0  0  0  0     0
MatPtAPNumeric         3 1.0 5.6292e-01 1.0 4.41e+08 1.0 0.0e+00 0.0e+00 0.0e+00  6  4  0  0  0  10  4  0  0  0   784
MatTrnMatMultSym       1 1.0 1.0488e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 12  0  0  0  0  20  0  0  0  0     0
MatGetSymTransR        3 1.0 3.0149e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               79 1.0 5.2332e-02 1.0 3.65e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1  4  0  0  0   1  4  0  0  0  6979
VecNorm               84 1.0 2.5005e-03 1.0 3.19e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 12770
VecScale              84 1.0 3.9795e-03 1.0 1.60e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  4012
VecCopy              464 1.0 1.1849e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               363 1.0 5.3346e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                6 1.0 4.8217e-04 1.0 2.06e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  4276
VecAYPX              918 1.0 4.0377e-02 1.0 1.06e+08 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   1  1  0  0  0  2628
VecAXPBYCZ           306 1.0 1.7107e-02 1.0 1.33e+08 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  7753
VecMAXPY              84 1.0 5.6828e-02 1.0 3.96e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1  4  0  0  0   1  4  0  0  0  6962
VecPointwiseMult     645 1.0 3.8111e-02 1.0 5.59e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   1  1  0  0  0  1467
VecNormalize          84 1.0 6.5369e-03 1.0 4.79e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7327
KSPSetUp               9 1.0 5.5035e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.8969e+00 1.0 9.07e+09 1.0 0.0e+00 0.0e+00 0.0e+00 32 91  0  0  0  54 91  0  0  0  3133
KSPGMRESOrthog        79 1.0 1.0520e-01 1.0 7.30e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1  7  0  0  0   2  7  0  0  0  6943
PCSetUp_GAMG+          1 1.0 2.4697e+00 1.0 8.95e+08 1.0 0.0e+00 0.0e+00 0.0e+00 28  9  0  0  0  46  9  0  0  0   362
 PCGAMGCreateG         3 1.0 2.8094e-01 1.0 1.14e+07 1.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   5  0  0  0  0    40
 GAMG Coarsen          6 1.0 1.0799e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 12  0  0  0  0  20  0  0  0  0     0
  GAMG MIS/Agg         3 1.0 1.0647e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 12  0  0  0  0  20  0  0  0  0     0
 PCGAMGProl            3 1.0 1.1103e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
  GAMG Prol-col        3 1.0 6.8758e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
  GAMG Prol-lift       3 1.0 1.0500e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
 PCGAMGOptProl         3 1.0 2.7735e-01 1.0 4.43e+08 1.0 0.0e+00 0.0e+00 0.0e+00  3  4  0  0  0   5  4  0  0  0  1596
  GAMG smooth          3 1.0 1.5133e-01 1.0 6.79e+07 1.0 0.0e+00 0.0e+00 0.0e+00  2  1  0  0  0   3  1  0  0  0   449
 PCGAMGCreateL         3 1.0 8.1506e-01 1.0 4.41e+08 1.0 0.0e+00 0.0e+00 0.0e+00  9  4  0  0  0  15  4  0  0  0   541
  GAMG PtAP            3 1.0 8.1506e-01 1.0 4.41e+08 1.0 0.0e+00 0.0e+00 0.0e+00  9  4  0  0  0  15  4  0  0  0   541
PCGAMG Squ l00         1 1.0 1.0488e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 12  0  0  0  0  20  0  0  0  0     0
PCGAMG Gal l00         1 1.0 7.9427e-01 1.0 4.19e+08 1.0 0.0e+00 0.0e+00 0.0e+00  9  4  0  0  0  15  4  0  0  0   528
PCGAMG Opt l00         1 1.0 1.0005e-01 1.0 6.09e+07 1.0 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   2  1  0  0  0   609
PCGAMG Gal l01         1 1.0 2.0699e-02 1.0 2.19e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  1059
PCGAMG Opt l01         1 1.0 2.3981e-03 1.0 1.91e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   798
PCGAMG Gal l02         1 1.0 8.7253e-05 1.0 9.78e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  1121
PCGAMG Opt l02         1 1.0 5.6299e-05 1.0 4.35e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   772
PCSetUp                2 1.0 2.4698e+00 1.0 8.95e+08 1.0 0.0e+00 0.0e+00 0.0e+00 28  9  0  0  0  46  9  0  0  0   362
PCSetUpOnBlocks       51 1.0 7.4239e-05 1.0 1.29e+02 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     2
PCApply               51 1.0 2.3017e+00 1.0 6.88e+09 1.0 0.0e+00 0.0e+00 0.0e+00 26 69  0  0  0  43 69  0  0  0  2990

--- Event Stage 4: post

BuildTwoSided          1 1.0 9.2880e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin        1 1.0 1.1189e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
VecScatterEnd          1 1.0 1.0330e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetGraph             1 1.0 1.9278e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0  24  0  0  0  0     0
SFSetUp                1 1.0 1.9897e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0  25  0  0  0  0     0
SFPack                 1 1.0 1.0200e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack               1 1.0 1.0400e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
------------------------------------------------------------------------------------------------------------------------

Object Type          Creations   Destructions. Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     0              1
              Viewer     0              1

--- Event Stage 1: init

              Matrix     1              0
              Vector     2              0

--- Event Stage 2: build

              Matrix     1              0
              Vector     2              1

--- Event Stage 3: solve

           Container     6              3
              Matrix    32             25
      Matrix Coarsen     3              3
              Vector   124             67
       Krylov Solver     9              3
      Preconditioner     9              3
              Viewer     2              1
         PetscRandom     3              3
           Index Set     9              6
    Distributed Mesh     7              3
   Star Forest Graph    14              6
     Discrete System     7              3
           Weak Form     7              3

--- Event Stage 4: post

              Vector     2              2
           Index Set     1              1
   Star Forest Graph     1              1
========================================================================================================================
Average time to get PetscTime(): 1.55e-08
#PETSc Option Table entries:
-eps_view # (source: command line)
-ksp_view # (source: command line)
-log_view # (source: command line)
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --download-openblas --download-mumps --download-scalapack --download-slepc --with-debugging=no --with-fortran-bindings=0 COPTFLAGS=-O3 CXXOPTFLAGS=-O3 FOPTFLAGS=-O3 --force
-----------------------------------------
Libraries compiled on 2024-05-16 22:18:29 on LIN54Z7SQ3 
Machine characteristics: Linux-6.5.0-35-generic-x86_64-with-glibc2.35
Using PETSc directory: /home/jtheler/libs/petsc
Using PETSc arch: release-gnu
-----------------------------------------

Using C compiler: mpicc  -fPIC -Wall -Wwrite-strings -Wno-unknown-pragmas -Wno-lto-type-mismatch -Wno-stringop-overflow -fstack-protector -fvisibility=hidden -O3  
Using Fortran compiler: mpif90  -fPIC -Wall -ffree-line-length-none -ffree-line-length-0 -Wno-lto-type-mismatch -Wno-unused-dummy-argument -O3    
-----------------------------------------

Using include paths: -I/home/jtheler/libs/petsc/include -I/home/jtheler/libs/petsc/release-gnu/include
-----------------------------------------

Using C linker: mpicc
Using Fortran linker: mpif90
Using libraries: -Wl,-rpath,/home/jtheler/libs/petsc/release-gnu/lib -L/home/jtheler/libs/petsc/release-gnu/lib -lpetsc -Wl,-rpath,/home/jtheler/libs/petsc/release-gnu/lib -L/home/jtheler/libs/petsc/release-gnu/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/11 -L/usr/lib/gcc/x86_64-linux-gnu/11 -ldmumps -lmumps_common -lpord -lpthread -lscalapack -lopenblas -lm -lX11 -lmpichfort -lmpich -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lstdc++ -lquadmath
-----------------------------------------

WARNING! There are options you set that were not used!
WARNING! could be spelling mistake, etc!
There is one unused database option. It is:
Option left: name:-eps_view (no value) source: command line
